{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ebb6a6",
   "metadata": {},
   "source": [
    "# Telecom X — ETL + EDA + Modelado\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/flacoca1970/Desafio_2/blob/main/notebooks/TelecomX_LATAM_inyectado.ipynb)\n",
    "\n",
    "Este notebook ejecuta el pipeline del desafío: **Extracción → Transformación → EDA → Model-ready → Baseline**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aeab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install imbalanced-learn --upgrade\n",
    "import os, io, json, ast, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from pandas import json_normalize\n",
    "print(\"Librerías cargadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aa91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de extracción\n",
    "USE_API = False\n",
    "API_URL = \"https://<tu_api>/endpoint\"\n",
    "LOCAL_JSON_PATH = \"/content/TelecomX_Data.json\"\n",
    "\n",
    "def robust_load_json_dataframe_from_str(raw: str) -> pd.DataFrame:\n",
    "    raw = raw.strip()\n",
    "    try:\n",
    "        obj = json.loads(raw)\n",
    "        if isinstance(obj, list):\n",
    "            return pd.DataFrame(obj)\n",
    "        if isinstance(obj, dict):\n",
    "            for key in [\"data\",\"items\",\"results\",\"records\",\"rows\"]:\n",
    "                if key in obj and isinstance(obj[key], list):\n",
    "                    return pd.DataFrame(obj[key])\n",
    "            return pd.DataFrame([obj])\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        df = pd.read_json(io.StringIO(raw), lines=True)\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            return df\n",
    "    except Exception:\n",
    "        pass\n",
    "    return pd.read_json(io.StringIO(raw))\n",
    "\n",
    "def robust_load_json_dataframe(path: str) -> pd.DataFrame:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw = f.read()\n",
    "    return robust_load_json_dataframe_from_str(raw)\n",
    "\n",
    "def parse_maybe_dict(x):\n",
    "    if isinstance(x, dict):\n",
    "        return x\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    s = str(x).strip()\n",
    "    if not (s.startswith(\"{\") and s.endswith(\"}\")):\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def flatten_telecomx(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    nested_candidates = [c for c in df.columns if c.lower() in [\"customer\",\"phone\",\"internet\",\"account\"]]\n",
    "    flat_parts = []\n",
    "    for c in nested_candidates:\n",
    "        parsed = df[c].apply(parse_maybe_dict)\n",
    "        part = json_normalize(parsed.dropna())\n",
    "        part = part.reindex(parsed.index)\n",
    "        part.columns = [f\"{c}__{col}\" for col in part.columns]\n",
    "        flat_parts.append(part)\n",
    "    out = df.drop(columns=nested_candidates, errors=\"ignore\").copy()\n",
    "    if flat_parts:\n",
    "        extra = pd.concat(flat_parts, axis=1)\n",
    "        out = pd.concat([out, extra], axis=1)\n",
    "    return out\n",
    "\n",
    "def standardize_churn(s: pd.Series) -> pd.Series:\n",
    "    if s.dtype == bool:\n",
    "        return s.map({True:\"Yes\", False:\"No\"})\n",
    "    if np.issubdtype(s.dropna().infer_objects().dtype, np.number):\n",
    "        return s.map({1:\"Yes\", 0:\"No\"})\n",
    "    ss = s.astype(str).str.strip().str.lower().replace({\"nan\": np.nan, \"none\": np.nan, \"\": np.nan})\n",
    "    return ss.map(lambda x: \"Yes\" if x==\"yes\" else (\"No\" if x==\"no\" else np.nan))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracción\n",
    "if USE_API:\n",
    "    import requests\n",
    "    r = requests.get(API_URL, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    df = robust_load_json_dataframe_from_str(r.text)\n",
    "else:\n",
    "    df = robust_load_json_dataframe(LOCAL_JSON_PATH)\n",
    "print(\"Shape inicial:\", df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9416104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación y EDA rápida\n",
    "df_flat = flatten_telecomx(df)\n",
    "if \"Churn\" in df_flat.columns:\n",
    "    df_flat[\"Churn\"] = standardize_churn(df_flat[\"Churn\"])\n",
    "\n",
    "for cand in [\"account__MonthlyCharges\",\"account__TotalCharges\",\"account__tenure\",\"MonthlyCharges\",\"TotalCharges\",\"tenure\",\"Tenure\"]:\n",
    "    if cand in df_flat.columns:\n",
    "        df_flat[cand] = pd.to_numeric(df_flat[cand], errors=\"coerce\")\n",
    "\n",
    "print(\"Shape aplanado:\", df_flat.shape)\n",
    "df_flat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a89c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tasa global y por categorías\n",
    "def churn_rate_by(df, cat_col):\n",
    "    m = df[\"Churn\"].isin([\"Yes\",\"No\"]) & df[cat_col].notna()\n",
    "    if not m.any(): return None\n",
    "    t = df.loc[m, [cat_col, \"Churn\"]].copy()\n",
    "    rate = t.groupby(cat_col)[\"Churn\"].apply(lambda s: (s==\"Yes\").mean()).rename(\"churn_rate\").reset_index()\n",
    "    return rate.sort_values(\"churn_rate\", ascending=False)\n",
    "\n",
    "def plot_bar(rate_df, title, xcol):\n",
    "    if rate_df is None or rate_df.empty: return\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.bar(rate_df[xcol].astype(str), rate_df[\"churn_rate\"].values)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"Tasa de churn\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "known = df_flat[\"Churn\"].isin([\"Yes\",\"No\"]) if \"Churn\" in df_flat.columns else pd.Series(False, index=df_flat.index)\n",
    "if known.any():\n",
    "    print(\"Tasa global de churn:\", round(100 * (df_flat.loc[known, \"Churn\"]==\"Yes\").mean(), 2), \"%\")\n",
    "\n",
    "for col, label in [\n",
    "    (\"account__Contract\", \"Contract\"),\n",
    "    (\"account__PaymentMethod\", \"PaymentMethod\"),\n",
    "    (\"internet__InternetService\", \"InternetService\"),\n",
    "]:\n",
    "    if col in df_flat.columns:\n",
    "        rate = churn_rate_by(df_flat, col)\n",
    "        plot_bar(rate, f\"Tasa de churn por {label}\", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15534846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-ready y baseline\n",
    "assert \"Churn\" in df_flat.columns, \"No se encontró 'Churn' tras aplanar. Revisa el JSON.\"\n",
    "df_model = df_flat.dropna(subset=[\"Churn\"]).copy()\n",
    "df_model[\"Churn\"] = df_model[\"Churn\"].map({\"Yes\":1, \"No\":0})\n",
    "\n",
    "y = df_model[\"Churn\"]\n",
    "X = df_model.drop(columns=[\"Churn\", \"customerID\"], errors=\"ignore\")\n",
    "\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "num_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())])\n",
    "cat_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "pre = ColumnTransformer([(\"num\", num_pipe, num_cols), (\"cat\", cat_pipe, cat_cols)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "clf = Pipeline([(\"pre\", pre), (\"model\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))])\n",
    "clf.fit(X_train, y_train)\n",
    "proba = clf.predict_proba(X_test)[:,1]\n",
    "pred  = (proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, proba))\n",
    "print(\"PR-AUC:\",  average_precision_score(y_test, proba))\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f371c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variante balanceada con RandomOverSampler (sin fuga de datos)\n",
    "imb_clf = ImbPipeline([(\"pre\", pre), (\"ros\", RandomOverSampler(random_state=42)), (\"model\", LogisticRegression(max_iter=1000))])\n",
    "imb_clf.fit(X_train, y_train)\n",
    "proba2 = imb_clf.predict_proba(X_test)[:,1]\n",
    "pred2  = (proba2 >= 0.5).astype(int)\n",
    "print(\"ROC-AUC (ROS):\", roc_auc_score(y_test, proba2))\n",
    "print(\"PR-AUC  (ROS):\", average_precision_score(y_test, proba2))\n",
    "print(classification_report(y_test, pred2, digits=3))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
