{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1caec00f",
   "metadata": {},
   "source": [
    "\n",
    "# Telecom X — ETL + EDA + Modelado (100% en Colab)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/flacoca1970/Desafio_2/blob/main/notebooks/TelecomX_LATAM_colab.ipynb)\n",
    "\n",
    "Este cuaderno ejecuta **todo el flujo**: **ETL → EDA → Model Zoo con GridSearch → Calibración (Platt/Isotónica) → Curva de Ganancia y Umbral de Negocio → Informe automático**.\n",
    "\n",
    "> **No hay scripts externos ni Makefile**; todo corre desde aquí.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7380cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalación de dependencias (solo si estás en Colab)\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    !pip -q install imbalanced-learn >/dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5973f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports y configuración\n",
    "import os, io, json, ast, warnings\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pandas import json_normalize\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, precision_recall_curve, roc_curve,\n",
    "                             confusion_matrix, classification_report, ConfusionMatrixDisplay)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88dac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Parámetros de ejecución\n",
    "# =========================\n",
    "USE_API = False\n",
    "API_URL = \"https://<tu_api>/endpoint\"  # usar si USE_API=True\n",
    "\n",
    "LOCAL_JSON_PATH = \"/content/TelecomX_Data.json\"  # sube el archivo a /content\n",
    "VALUE_RETAIN = 100.0   # valor por retener churner\n",
    "COST_CONTACT = 5.0     # costo por contactar a un cliente\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c9b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Funciones de ETL\n",
    "# =========================\n",
    "def robust_load_json_dataframe_from_str(raw: str) -> pd.DataFrame:\n",
    "    raw = raw.strip()\n",
    "    try:\n",
    "        obj = json.loads(raw)\n",
    "        if isinstance(obj, list):\n",
    "            return pd.DataFrame(obj)\n",
    "        if isinstance(obj, dict):\n",
    "            for key in [\"data\",\"items\",\"results\",\"records\",\"rows\"]:\n",
    "                if key in obj and isinstance(obj[key], list):\n",
    "                    return pd.DataFrame(obj[key])\n",
    "            return pd.DataFrame([obj])\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        df = pd.read_json(io.StringIO(raw), lines=True)\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            return df\n",
    "    except Exception:\n",
    "        pass\n",
    "    return pd.read_json(io.StringIO(raw))\n",
    "\n",
    "def robust_load_json_dataframe(path: str) -> pd.DataFrame:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw = f.read()\n",
    "    return robust_load_json_dataframe_from_str(raw)\n",
    "\n",
    "def parse_maybe_obj(x):\n",
    "    if isinstance(x, (dict, list)):\n",
    "        return x\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    s = str(x).strip()\n",
    "    if (s.startswith(\"{\") and s.endswith(\"}\")) or (s.startswith(\"[\") and s.endswith(\"]\")):\n",
    "        try:\n",
    "            return json.loads(s)\n",
    "        except Exception:\n",
    "            try:\n",
    "                return ast.literal_eval(s)\n",
    "            except Exception:\n",
    "                return None\n",
    "    return x\n",
    "\n",
    "def flatten_dot(df: pd.DataFrame, candidates=None) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    if candidates is None:\n",
    "        candidates = [c for c in out.columns if c.lower() in [\"customer\",\"phone\",\"internet\",\"account\"]] +                          [c for c in out.columns if out[c].apply(lambda v: isinstance(parse_maybe_obj(v), (dict,list))).any()]\n",
    "        candidates = list(dict.fromkeys(candidates))\n",
    "    parts = []\n",
    "    for c in candidates:\n",
    "        parsed = out[c].apply(parse_maybe_obj)\n",
    "        mask_dict = parsed.apply(lambda v: isinstance(v, dict))\n",
    "        if mask_dict.any():\n",
    "            part = json_normalize(parsed.where(mask_dict, None).dropna()).reindex(parsed.index)\n",
    "            part.columns = [f\"{c}.\"+col for col in part.columns]\n",
    "            parts.append(part)\n",
    "    if parts:\n",
    "        extra = pd.concat(parts, axis=1)\n",
    "        out = pd.concat([out.drop(columns=candidates, errors=\"ignore\"), extra], axis=1)\n",
    "    return out\n",
    "\n",
    "def standardize_yes_no(series: pd.Series) -> pd.Series:\n",
    "    s = series.astype(str).str.strip()\n",
    "    low = s.str.lower().replace({\"nan\": np.nan, \"none\": np.nan, \"\": np.nan})\n",
    "    mapped = low.map({\"yes\":\"Yes\",\"no\":\"No\",\"si\":\"Yes\",\"sí\":\"Yes\",\"true\":\"Yes\",\"false\":\"No\",\"1\":\"Yes\",\"0\":\"No\"})\n",
    "    out = pd.Series(np.where(mapped.isna(), s, mapped), index=series.index, dtype=\"object\")\n",
    "    return out.replace({\"\": np.nan, \"None\": np.nan, \"nan\": np.nan})\n",
    "\n",
    "def coerce_numeric(series: pd.Series) -> pd.Series:\n",
    "    return pd.to_numeric(series.astype(str).str.replace(r\"[,$% ]\",\"\", regex=True), errors=\"coerce\")\n",
    "\n",
    "def build_df_limpo(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    df1 = flatten_dot(df_raw)\n",
    "    if \"Churn\" in df1.columns:\n",
    "        df1[\"Churn\"] = standardize_yes_no(df1[\"Churn\"])\n",
    "    for c in df1.columns:\n",
    "        vals = df1[c].dropna().astype(str).str.lower().unique().tolist()\n",
    "        if len(vals) > 0 and set(vals).issubset({\"yes\",\"no\",\"true\",\"false\",\"1\",\"0\"}):\n",
    "            df1[c] = standardize_yes_no(df1[c])\n",
    "    for cand in [\"account.MonthlyCharges\",\"account.TotalCharges\",\"account.tenure\",\n",
    "                 \"customer.monthlyCharges\",\"customer.totalCharges\",\"customer.tenure\",\n",
    "                 \"MonthlyCharges\",\"TotalCharges\",\"tenure\",\"Tenure\",\n",
    "                 \"account.Charges.Monthly\",\"account.Charges.Total\"]:\n",
    "        if cand in df1.columns:\n",
    "            df1[cand] = coerce_numeric(df1[cand])\n",
    "    if \"account.Charges.Monthly\" in df1.columns and \"account.MonthlyCharges\" not in df1.columns:\n",
    "        df1 = df1.rename(columns={\"account.Charges.Monthly\":\"account.MonthlyCharges\"})\n",
    "    if \"account.Charges.Total\" in df1.columns and \"account.TotalCharges\" not in df1.columns:\n",
    "        df1 = df1.rename(columns={\"account.Charges.Total\":\"account.TotalCharges\"})\n",
    "    if \"customer.tenure\" not in df1.columns:\n",
    "        for alt in [\"account.tenure\",\"tenure\",\"Tenure\"]:\n",
    "            if alt in df1.columns:\n",
    "                df1 = df1.rename(columns={alt:\"customer.tenure\"}); break\n",
    "    pref = [\"customerID\",\"Churn\",\"account.Contract\",\"account.PaymentMethod\",\"internet.InternetService\",\n",
    "            \"customer.tenure\",\"account.MonthlyCharges\",\"account.TotalCharges\"]\n",
    "    cols = [c for c in pref if c in df1.columns] + [c for c in df1.columns if c not in pref]\n",
    "    return df1[cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e064af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Ejecución ETL\n",
    "# =========================\n",
    "if USE_API:\n",
    "    import requests\n",
    "    r = requests.get(API_URL, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    df_raw = robust_load_json_dataframe_from_str(r.text)\n",
    "else:\n",
    "    path = LOCAL_JSON_PATH if os.path.exists(LOCAL_JSON_PATH) else \"../data/raw/TelecomX_Data.json\"\n",
    "    df_raw = robust_load_json_dataframe(path)\n",
    "\n",
    "df_limpo = build_df_limpo(df_raw)\n",
    "print(\"df_limpo shape:\", df_limpo.shape)\n",
    "display(df_limpo.head(3))\n",
    "\n",
    "# Guardar para trazabilidad (opcional en Colab)\n",
    "os.makedirs(\"/content/data/interim\", exist_ok=True)\n",
    "df_limpo.to_csv(\"/content/data/interim/df_limpo.csv\", index=False)\n",
    "print(\"Guardado /content/data/interim/df_limpo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13627d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# EDA rápida\n",
    "# =========================\n",
    "def churn_rate(s):\n",
    "    return float(s.astype(str).str.lower().map({\"yes\":1,\"no\":0}).mean())\n",
    "\n",
    "if \"Churn\" in df_limpo.columns:\n",
    "    print(\"Tasa global de churn:\", round(100*churn_rate(df_limpo[\"Churn\"]), 2), \"%\")\n",
    "\n",
    "def churn_rate_by(df, col):\n",
    "    t = df[[col, \"Churn\"]].dropna()\n",
    "    r = t.groupby(col)[\"Churn\"].apply(lambda s: (s.astype(str).str.lower()==\"yes\").mean()).rename(\"churn_rate\").reset_index()\n",
    "    return r.sort_values(\"churn_rate\", ascending=False)\n",
    "\n",
    "for col, label in [(\"account.Contract\",\"Contract\"),\n",
    "                   (\"account.PaymentMethod\",\"PaymentMethod\"),\n",
    "                   (\"internet.InternetService\",\"InternetService\")]:\n",
    "    if col in df_limpo.columns:\n",
    "        rate = churn_rate_by(df_limpo, col)\n",
    "        plt.figure(figsize=(7,4))\n",
    "        plt.bar(rate[col].astype(str), rate[\"churn_rate\"].values)\n",
    "        plt.xticks(rotation=45, ha=\"right\"); plt.ylabel(\"Tasa de churn\"); plt.title(f\"Tasa por {label}\")\n",
    "        plt.show()\n",
    "        display(rate.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed979be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Preparación para modelado\n",
    "# =========================\n",
    "assert \"Churn\" in df_limpo.columns, \"No existe 'Churn' tras el ETL.\"\n",
    "y = df_limpo[\"Churn\"].astype(str).str.lower().map({\"yes\":1,\"no\":0}).values\n",
    "X = df_limpo.drop(columns=[\"Churn\",\"customerID\"], errors=\"ignore\")\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "num_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())])\n",
    "cat_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "pre = ColumnTransformer([(\"num\", num_pipe, num_cols), (\"cat\", cat_pipe, cat_cols)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2c43c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Model Zoo + GridSearch (selección por PR-AUC)\n",
    "# =========================\n",
    "models = {\n",
    "    \"logreg\": (LogisticRegression(max_iter=2000, class_weight=\"balanced\"),\n",
    "               {\"model__C\":[0.1,1,5,10]}),\n",
    "    \"rf\": (RandomForestClassifier(n_estimators=400, n_jobs=-1, random_state=RANDOM_STATE, class_weight=\"balanced\"),\n",
    "           {\"model__max_depth\":[None,8,14], \"model__min_samples_leaf\":[1,3,6]}),\n",
    "    \"gb\": (GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "           {\"model__n_estimators\":[200,400], \"model__learning_rate\":[0.05,0.1], \"model__max_depth\":[2,3]}),\n",
    "    \"hgb\": (HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "            {\"model__max_depth\":[None,10,14], \"model__learning_rate\":[0.05,0.1]}),\n",
    "    \"linsvc\": (LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE),\n",
    "               {\"model__C\":[0.5,1,5]}),\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "results = {}\n",
    "best_est, best_name, best_score = None, None, -1\n",
    "\n",
    "for name, (est, grid) in models.items():\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"model\", est)])\n",
    "    gs = GridSearchCV(pipe, param_grid=grid, scoring=\"average_precision\", cv=cv, n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    results[name] = gs.best_score_\n",
    "    if gs.best_score_ > best_score:\n",
    "        best_est, best_name, best_score = gs.best_estimator_, name, gs.best_score_\n",
    "\n",
    "print(\"Resultados PR-AUC (CV):\", results)\n",
    "print(\"Mejor modelo:\", best_name, \"PR-AUC (CV):\", round(best_score,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b4cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Calibración (Platt/Isotónica) y evaluación en Test\n",
    "# =========================\n",
    "pre_fitted = best_est.named_steps[\"pre\"].fit(X_train, y_train)\n",
    "Xtr = pre_fitted.transform(X_train)\n",
    "Xte = pre_fitted.transform(X_test)\n",
    "base = best_est.named_steps[\"model\"]\n",
    "\n",
    "if best_name == \"linsvc\":\n",
    "    cal_platt = CalibratedClassifierCV(base, method=\"sigmoid\", cv=3).fit(Xtr, y_train)\n",
    "    y_score_platt = cal_platt.predict_proba(Xte)[:,1]\n",
    "    cal_iso = CalibratedClassifierCV(base, method=\"isotonic\", cv=3).fit(Xtr, y_train)\n",
    "    y_score_iso = cal_iso.predict_proba(Xte)[:,1]\n",
    "    pr_platt = average_precision_score(y_test, y_score_platt)\n",
    "    pr_iso   = average_precision_score(y_test, y_score_iso)\n",
    "    if pr_iso >= pr_platt:\n",
    "        y_score, cal_used = y_score_iso, \"isotonic\"\n",
    "    else:\n",
    "        y_score, cal_used = y_score_platt, \"platt\"\n",
    "else:\n",
    "    cal_iso = CalibratedClassifierCV(base, method=\"isotonic\", cv=3).fit(Xtr, y_train)\n",
    "    y_score = cal_iso.predict_proba(Xte)[:,1]\n",
    "    cal_used = \"isotonic\"\n",
    "\n",
    "roc = roc_auc_score(y_test, y_score)\n",
    "pr  = average_precision_score(y_test, y_score)\n",
    "print(f\"ROC-AUC (test): {roc:.4f} | PR-AUC (test): {pr:.4f} | Calibración: {cal_used}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c92459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Curva de ganancia y umbral óptimo de negocio\n",
    "# =========================\n",
    "def business_profit(y_true, y_score, thr, value=VALUE_RETAIN, cost=COST_CONTACT):\n",
    "    y_pred = (y_score >= thr).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tp*value - (tp+fp)*cost\n",
    "\n",
    "thr_grid = np.linspace(0.01, 0.99, 99)\n",
    "profits = [business_profit(y_test, y_score, t) for t in thr_grid]\n",
    "best_thr = float(thr_grid[int(np.argmax(profits))])\n",
    "best_profit = float(np.max(profits))\n",
    "print(\"Umbral óptimo de negocio:\", round(best_thr,3), \"| Ganancia estimada:\", round(best_profit,2))\n",
    "\n",
    "prec, rec, _ = precision_recall_curve(y_test, y_score)\n",
    "plt.figure(figsize=(6,4)); plt.plot(rec, prec); plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall\"); plt.show()\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "plt.figure(figsize=(6,4)); plt.plot(fpr, tpr); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC\"); plt.show()\n",
    "plt.figure(figsize=(6,4)); plt.plot(thr_grid, profits); plt.axvline(best_thr, linestyle=\"--\"); plt.xlabel(\"Threshold\"); plt.ylabel(\"Profit\"); plt.title(\"Curva de Ganancia\"); plt.show()\n",
    "\n",
    "y_pred = (y_score >= best_thr).astype(int)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred), display_labels=[\"No\",\"Yes\"])\n",
    "disp.plot(cmap=None); plt.title(\"Confusion Matrix (umbral negocio)\"); plt.show()\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2183ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Guardado de métricas/artefactos (opcional)\n",
    "# =========================\n",
    "import json\n",
    "os.makedirs(\"/content/reports\", exist_ok=True)\n",
    "metrics = {\n",
    "    \"best_model\": str(best_name),\n",
    "    \"cv_best_pr_auc\": float(best_score),\n",
    "    \"test_roc_auc\": float(roc_auc_score(y_test, y_score)),\n",
    "    \"test_pr_auc\": float(average_precision_score(y_test, y_score)),\n",
    "    \"business_best_threshold\": float(best_thr),\n",
    "    \"business_best_profit\": float(best_profit),\n",
    "    \"value_retain\": float(VALUE_RETAIN),\n",
    "    \"cost_contact\": float(COST_CONTACT),\n",
    "    \"calibration\": cal_used\n",
    "}\n",
    "with open(\"/content/reports/metrics.json\",\"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print(\"Guardado /content/reports/metrics.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db68a35",
   "metadata": {},
   "source": [
    "## Informe automático\n",
    "La siguiente celda genera un archivo Markdown con el **resumen del ETL, EDA y Modelado** (incluye **umbral óptimo de negocio** y **matriz de confusión**).  \n",
    "El informe queda en `/content/reports/README_REPORT.md` y se exportan tablas EDA como CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d046378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de informe Markdown automático\n",
    "import os, json\n",
    "from sklearn.metrics import confusion_matrix\n",
    "os.makedirs(\"/content/reports\", exist_ok=True)\n",
    "\n",
    "def to_pct(x):\n",
    "    try: return f\"{100*float(x):.2f}%\"\n",
    "    except Exception: return \"—\"\n",
    "\n",
    "def churn_rate_by(df, col):\n",
    "    t = df[[col, \"Churn\"]].dropna()\n",
    "    r = t.groupby(col)[\"Churn\"].apply(lambda s: (s.astype(str).str.lower()==\"yes\").mean()).rename(\"churn_rate\").reset_index()\n",
    "    return r.sort_values(\"churn_rate\", ascending=False)\n",
    "\n",
    "eda_tables = []\n",
    "segments = [(\"account.Contract\",\"Contract\"),\n",
    "            (\"account.PaymentMethod\",\"PaymentMethod\"),\n",
    "            (\"internet.InternetService\",\"InternetService\")]\n",
    "for col, label in segments:\n",
    "    if col in df_limpo.columns:\n",
    "        rate = churn_rate_by(df_limpo, col)\n",
    "        rate.to_csv(f\"/content/reports/churn_rate_by_{label.lower()}.csv\", index=False)\n",
    "        eda_tables.append((label, rate))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, (y_score >= best_thr).astype(int)).ravel()\n",
    "\n",
    "lines = []\n",
    "lines.append(\"# Informe de Resultados — Telecom X\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"## 1. ETL (resumen)\")\n",
    "lines.append(f\"- Filas en `df_limpo`: **{df_limpo.shape[0]}** | Columnas: **{df_limpo.shape[1]}**\")\n",
    "present = [c for c in [\"Churn\",\"account.Contract\",\"account.PaymentMethod\",\"internet.InternetService\",\"customer.tenure\",\"account.MonthlyCharges\",\"account.TotalCharges\"] if c in df_limpo.columns]\n",
    "lines.append(\"- Columnas clave presentes: \" + (\", \".join(present) if present else \"—\"))\n",
    "if \"Churn\" in df_limpo.columns:\n",
    "    global_rate = df_limpo[\"Churn\"].astype(str).str.lower().map({\"yes\":1,\"no\":0}).mean()\n",
    "    lines.append(f\"- Tasa global de churn: **{to_pct(global_rate)}**\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"## 2. EDA (tasas de churn por segmento)\")\n",
    "if eda_tables:\n",
    "    for label, tbl in eda_tables:\n",
    "        lines.append(f\"**{label}** (Top categorías por churn):\")\n",
    "        head = tbl.head(10).copy()\n",
    "        cols = head.columns.tolist()\n",
    "        lines.append(\"| \" + \" | \".join(cols) + \" |\")\n",
    "        lines.append(\"|\" + \"|\".join([\"---\"]*len(cols)) + \"|\")\n",
    "        for _, row in head.iterrows():\n",
    "            lines.append(\"| \" + \" | \".join([str(row[cols[0]]), to_pct(row['churn_rate'])]) + \" |\")\n",
    "        lines.append(\"\")\n",
    "else:\n",
    "    lines.append(\"_No se encontraron columnas de segmentación esperadas._\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"## 3. Modelado\")\n",
    "lines.append(f\"- **Mejor modelo (CV por PR-AUC)**: **{best_name}**\")\n",
    "lines.append(f\"- **PR-AUC (CV)**: **{best_score:.4f}**\")\n",
    "lines.append(f\"- **ROC-AUC (test)**: **{roc_auc_score(y_test, y_score):.4f}**\")\n",
    "lines.append(f\"- **PR-AUC (test)**: **{average_precision_score(y_test, y_score):.4f}**\")\n",
    "lines.append(f\"- **Calibración**: **{cal_used}**\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"## 4. Umbral de negocio\")\n",
    "lines.append(f\"- **Threshold óptimo**: **{best_thr:.3f}**\")\n",
    "lines.append(f\"- **Ganancia estimada**: **{best_profit:.2f}** (VALUE_RETAIN={VALUE_RETAIN}, COST_CONTACT={COST_CONTACT})\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"**Matriz de confusión (umbral de negocio):**\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"|       | Pred No | Pred Yes |\")\n",
    "lines.append(\"|-------|---------|----------|\")\n",
    "lines.append(f\"| Real No  | {tn} | {fp} |\")\n",
    "lines.append(f\"| Real Yes | {fn} | {tp} |\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"## 5. Conclusiones\")\n",
    "lines.append(\"- El churn se **concentra** en **Month-to-month**, **Electronic check** y **Fiber optic**.\")\n",
    "lines.append(\"- El umbral óptimo maximiza **ganancia neta** equilibrando recall de churners y costo de contacto.\")\n",
    "lines.append(\"- Recomendaciones: incentivar **contratos anuales**, migrar a **pagos automáticos**, activar **retención temprana** y reforzar soporte para **fibra**.\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"_Informe generado automáticamente desde el Notebook._\")\n",
    "\n",
    "md_path = \"/content/reports/README_REPORT.md\"\n",
    "with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(\"Informe guardado en:\", md_path)\n",
    "print(\"Tablas EDA guardadas en /content/reports/churn_rate_by_*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f5c980",
   "metadata": {},
   "source": [
    "## Exportar Top N clientes en riesgo (para CRM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d1cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar Top N clientes en riesgo con columnas útiles para CRM\n",
    "N = 500  # puedes ajustar\n",
    "try:\n",
    "    # Alinear índices con X_test/y_test\n",
    "    salida = df_limpo.loc[X_test.index].copy()\n",
    "except Exception:\n",
    "    # Como fallback, concatenar probas directamente si dimensiones permiten\n",
    "    salida = df_limpo.iloc[-len(y_score):].copy()\n",
    "salida[\"churn_score\"] = y_score\n",
    "salida[\"flag_churn_risk\"] = (y_score >= best_thr).astype(int)\n",
    "topN = salida.sort_values(\"churn_score\", ascending=False).head(N)\n",
    "os.makedirs(\"/content/reports\", exist_ok=True)\n",
    "top_path = \"/content/reports/clientes_en_riesgo_topN.csv\"\n",
    "topN.to_csv(top_path, index=False)\n",
    "print(\"Exportado:\", top_path)\n",
    "topN.head(10)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
